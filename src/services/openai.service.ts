import OpenAI from 'openai';
import { loadApiKey } from './storage.service';

export class OpenAIService {
  private static instance: OpenAIService | null = null;
  private openai: OpenAI | null = null;
  private model: string = 'gpt-4o-2024-08-06';

  static getInstance(): OpenAIService {
    if (!OpenAIService.instance) {
      OpenAIService.instance = new OpenAIService();
      // ìƒì„± ì‹œ ìë™ìœ¼ë¡œ ì €ì¥ëœ API í‚¤ ë¡œë“œ ì‹œë„
      OpenAIService.instance.autoInitialize();
    }
    return OpenAIService.instance;
  }

  private autoInitialize(): void {
    const apiKey = loadApiKey();
    if (apiKey) {
      console.log('ğŸ”‘ ì €ì¥ëœ API í‚¤ ìë™ ë¡œë“œë¨');
      this.initialize(apiKey);
    } else {
      console.log('âš ï¸ ì €ì¥ëœ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.');
    }
  }

  initialize(apiKey: string): void {
    this.openai = new OpenAI({
      apiKey,
      dangerouslyAllowBrowser: true
    });
  }

  // API í‚¤ê°€ ìƒˆë¡œ ì„¤ì •ë˜ì—ˆì„ ë•Œ ë‹¤ì‹œ ë¡œë“œ
  reloadApiKey(): boolean {
    const apiKey = loadApiKey();
    if (apiKey) {
      console.log('ğŸ”„ API í‚¤ ì¬ë¡œë“œë¨');
      this.initialize(apiKey);
      return true;
    }
    return false;
  }

  async validateKey(apiKey: string): Promise<boolean> {
    try {
      const tempClient = new OpenAI({
        apiKey,
        dangerouslyAllowBrowser: true
      });
      
      // Simple validation call with minimal token usage
      const response = await tempClient.chat.completions.create({
        model: 'gpt-4o',
        messages: [{ role: 'user', content: 'test' }],
        max_tokens: 10
      });
      
      return !!response;
    } catch (error) {
      console.error('API key validation failed:', error);
      return false;
    }
  }

  getClient(): OpenAI {
    if (!this.openai) {
      throw new Error('OpenAI client not initialized. Please set API key first.');
    }
    return this.openai;
  }

  async generateCompletion(prompt: string, context?: string): Promise<{ content: string; usage?: any }> {
    const client = this.getClient();
    
    const response = await client.chat.completions.create({
      model: 'gpt-4o',
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.8, // ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ë†’ì€ ì˜¨ë„
      max_tokens: 4000
    });

    // í† í° ì‚¬ìš©ëŸ‰ ë¡œê·¸ (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
    if (response.usage && context) {
      console.group(`ğŸ”¥ í† í° ì‚¬ìš©ëŸ‰ - ${context}`);
      console.log(`ğŸ“¥ ì…ë ¥ í† í°: ${response.usage.prompt_tokens?.toLocaleString() || 0}`);
      console.log(`ğŸ“¤ ì¶œë ¥ í† í°: ${response.usage.completion_tokens?.toLocaleString() || 0}`);
      console.log(`ğŸ”¢ ì´ í† í°: ${response.usage.total_tokens?.toLocaleString() || 0}`);
      console.groupEnd();
    }

    return {
      content: response.choices[0]?.message?.content || '',
      usage: response.usage
    };
  }

  // Structured Outputì„ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„±
  async generateStructuredCompletion(
    prompt: string, 
    schema: any, 
    context?: string
  ) {
    const client = this.getClient();
    
    const response = await client.chat.completions.create({
      model: this.model,
      messages: [
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.3, // êµ¬ì¡°í™”ëœ ì¶œë ¥ì€ ë‚®ì€ temperature ì‚¬ìš©
      max_tokens: 4000,
      response_format: {
        type: "json_schema",
        json_schema: {
          name: "wireframe_response",
          schema: schema,
          strict: true
        }
      }
    });

    // í† í° ì‚¬ìš©ëŸ‰ ë¡œê·¸ (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
    if (response.usage && context) {
      console.group(`ğŸ”¥ í† í° ì‚¬ìš©ëŸ‰ - ${context} (Structured)`);
      console.log(`ğŸ“¥ ì…ë ¥ í† í°: ${response.usage.prompt_tokens?.toLocaleString() || 0}`);
      console.log(`ğŸ“¤ ì¶œë ¥ í† í°: ${response.usage.completion_tokens?.toLocaleString() || 0}`);
      console.log(`ğŸ”¢ ì´ í† í°: ${response.usage.total_tokens?.toLocaleString() || 0}`);
      console.groupEnd();
    }

    const content = response.choices[0]?.message?.content || '{}';
    
    try {
      const parsed = JSON.parse(content);
      return {
        content: parsed,
        rawContent: content,
        usage: response.usage
      };
    } catch (error) {
      console.error('Failed to parse structured response:', error);
      throw new Error('Invalid structured response from OpenAI');
    }
  }

  // Step2ì—ì„œ ì‚¬ìš©í•˜ëŠ” íŠ¹í™”ëœ completion ë©”ì„œë“œ
  async createCompletion(params: {
    model: string;
    messages: Array<{ role: string; content: string }>;
    temperature: number;
    top_p: number;
    max_tokens: number;
    stop: string[];
  }) {
    const client = this.getClient();
    
    const response = await client.chat.completions.create({
      model: params.model,
      messages: params.messages as any,
      temperature: params.temperature,
      top_p: params.top_p,
      max_tokens: params.max_tokens,
      stop: params.stop
    });

    return response;
  }
}